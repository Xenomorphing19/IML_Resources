{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IML_Q6_IIT2019003.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_KZ_y922C5V"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyYtaRpJ8dj6"
      },
      "source": [
        "def normal_equation(X,Y):\n",
        "  W = np.transpose(X)\n",
        "  W = np.dot(W,X)\n",
        "  # print(\"determinant: \",np.linalg.det(W));\n",
        "  W = np.linalg.inv(W)\n",
        "  W = np.dot(W,np.transpose(X))\n",
        "  W = np.dot(W,Y)\n",
        "  return W\n",
        "  "
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3I-hCD-Khv"
      },
      "source": [
        "def normal_equation_with_regularization(X,Y,lamb):\n",
        "  W = np.transpose(X)\n",
        "  W = np.dot(W,X)\n",
        "  one = np.identity(X.shape[1])\n",
        "  one[0, 0] = 0\n",
        "  W = W + lamb*one\n",
        "  W = np.linalg.inv(W)\n",
        "  W = np.dot(W,np.transpose(X))\n",
        "  W = np.dot(W,Y)\n",
        "  return W"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFOn24iZ5jQs"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/IML datasets/Housing Price data set.csv\")\n",
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "m = df.shape[0]\n",
        "n = 4\n",
        "X = np.array([np.ones(m, np.float32), df['lotsize'].to_numpy(),df['bedrooms'].to_numpy(), df['bathrms'].to_numpy()]).T\n",
        "Y = df['price'].to_numpy()\n",
        "X_train, X_test, Y_train, Y_test = X[:382], X[382:], Y[:382], Y[382:]"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmdtzZ38Pqa2"
      },
      "source": [
        "a).  Normal equations  with  and without regularization and compare their performances in terms of % error in prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XQf3cod7swJ",
        "outputId": "a663c279-1f6e-4dbc-f779-822667c71f35"
      },
      "source": [
        "print(\"Normal Equation without Regularization:\")\n",
        "W = normal_equation(X_train,Y_train)\n",
        "print()\n",
        "print(\"Weights without regularization: \", W)\n",
        "temp = np.dot(X_test, W)\n",
        "error = abs(Y_test - temp)/Y_test\n",
        "error = np.sum(error)/164\n",
        "print()\n",
        "print(\"Error without regularization: \",error*100,\"%\")\n",
        "print()"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Equation without Regularization:\n",
            "\n",
            "Weights without regularization:  [-4.89492370e+03  5.93101241e+00  5.52857201e+03  1.90100176e+04]\n",
            "\n",
            "Error without regularization:  18.666490014537153 %\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xjhjUONMVrW",
        "outputId": "e2352290-1b29-4c4a-e92c-7d49b3103eb6"
      },
      "source": [
        "lamb = [0.01,0.1,1,5,10,25,50,90,100]\n",
        "print(\"Normal Equation with Regularization:\\n\")\n",
        "cnt=1\n",
        "for l in lamb:\n",
        "  print(cnt,\". \")\n",
        "  W = normal_equation_with_regularization(X_train,Y_train,l)\n",
        "  print(\"Weights with regularization: \", W)\n",
        "  temp = np.dot(X_test, W)\n",
        "  error = abs(Y_test - temp)/Y_test\n",
        "  error = np.sum(error)/164\n",
        "  print()\n",
        "  print(\"Error with regularization(lambda = : \",l,\"): \",error*100,\"%\")\n",
        "  print()\n",
        "  cnt+=1\n"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normal Equation with Regularization:\n",
            "\n",
            "1 . \n",
            "Weights with regularization:  [-4.89345776e+03  5.93113372e+00  5.52878565e+03  1.90079252e+04]\n",
            "\n",
            "Error with regularization(lambda = :  0.01 ):  18.666398680295625 %\n",
            "\n",
            "2 . \n",
            "Weights with regularization:  [-4.88027124e+03  5.93222442e+00  5.53070263e+03  1.89891168e+04]\n",
            "\n",
            "Error with regularization(lambda = :  0.1 ):  18.665577642838638 %\n",
            "\n",
            "3 . \n",
            "Weights with regularization:  [-4.74908590e+03  5.94302649e+00  5.54931487e+03  1.88032408e+04]\n",
            "\n",
            "Error with regularization(lambda = :  1 ):  18.657462199267325 %\n",
            "\n",
            "4 . \n",
            "Weights with regularization:  [-4.18050351e+03  5.98885079e+00  5.62062896e+03  1.80228754e+04]\n",
            "\n",
            "Error with regularization(lambda = :  5 ):  18.625887429784058 %\n",
            "\n",
            "5 . \n",
            "Weights with regularization:  [-3.50092027e+03  6.04161991e+00  5.68703068e+03  1.71410143e+04]\n",
            "\n",
            "Error with regularization(lambda = :  10 ):  18.600616738322802 %\n",
            "\n",
            "6 . \n",
            "Weights with regularization:  [-1.64237792e+03  6.17613332e+00  5.77638338e+03  1.49783222e+04]\n",
            "\n",
            "Error with regularization(lambda = :  25 ):  18.565829327160163 %\n",
            "\n",
            "7 . \n",
            "Weights with regularization:  [9.77862770e+02 6.34592925e+00 5.71557057e+03 1.24335704e+04]\n",
            "\n",
            "Error with regularization(lambda = :  50 ):  18.61603052031687 %\n",
            "\n",
            "8 . \n",
            "Weights with regularization:  [4.28932458e+03 6.53594447e+00 5.40744056e+03 9.84191554e+03]\n",
            "\n",
            "Error with regularization(lambda = :  90 ):  18.771650624691592 %\n",
            "\n",
            "9 . \n",
            "Weights with regularization:  [4.99009668e+03 6.57342436e+00 5.31652901e+03 9.36286852e+03]\n",
            "\n",
            "Error with regularization(lambda = :  100 ):  18.80775550888755 %\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs9AdDWWPx3X"
      },
      "source": [
        "b). Design Predictor using Batch Gradient Descent Algorithm, Stochastic Gradient Algorithm and mini batch Gradient Descent algorithms (determining minibatch size is your choice- here it could be 10, 20, 30 etc.) with and without feature scaling and compare their performances in terms of % error in prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwXVoJZcP2t2"
      },
      "source": [
        "def batch_gradient_descent(X,Y,alpha,itr):\n",
        "  W = np.zeros((n, 1))\n",
        "  for i in range(0,itr):\n",
        "     H = np.dot(W.T, X)\n",
        "     Z = H - Y\n",
        "     dW = np.dot(X, Z.T)\n",
        "     W = W - (alpha*dW)/(X.shape[1])\n",
        "     J = np.sum(Z**2)/(2*m)\n",
        "  return W"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-W-X8JOxW6Z"
      },
      "source": [
        "def scaling(X):\n",
        "  X1 = copy.deepcopy(X)\n",
        "  stdv = np.std(X1[:, 0:], axis=0)\n",
        "  stdv[0] = 1\n",
        "  mean = np.mean(X1[:, 0:], axis=0)\n",
        "  mean[0] = 0\n",
        "  X1[:, 0:] = (X1[:, 0:]-mean) / stdv\n",
        "  return X1,mean,stdv"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2Ee1G62w9-q"
      },
      "source": [
        "def batch_gradient_descent_with_scaling(X_train,Y_train,X_test,Y_test,alpha,itr):\n",
        "  X_train, MEAN, STDV = scaling(X_train)\n",
        "  X_test = (X_test - MEAN) / STDV\n",
        "  X_train, X_test = X_train.T, X_test.T\n",
        "  W = np.zeros((n, 1))\n",
        "  for i in range(0, itr):\n",
        "      H = np.dot(W.T, X_train)\n",
        "      Z = H - Y_train\n",
        "      dW = np.dot(X_train, Z.T)\n",
        "      W = W - (alpha*dW)/(X_train.shape[1])\n",
        "      J = np.sum(Z**2)/(2*m)\n",
        "  print(\"Weights with scaling: \\n\", W)\n",
        "  print()\n",
        "  pred = np.dot(W.T, X_test)\n",
        "  error = abs(Y_test - pred)/Y_test\n",
        "  error = np.sum(error, axis=1)/X_test.shape[1]\n",
        "  print(\"Error with Scaling: \",error*100,\"%\")"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vFoW-dtrPUs",
        "outputId": "47ab471b-46d3-469a-c4e6-530ea5f2bded"
      },
      "source": [
        "print(\"Batch Gradient Descent Without Scaling:\")\n",
        "print()\n",
        "W = batch_gradient_descent(X_train.T,Y_train,0.000000001, 10000)\n",
        "print(\"Weights without scaling:\\n\", W)\n",
        "print()\n",
        "pred = np.dot(W.T, X_test.T)\n",
        "error = abs(Y_test - pred)/Y_test\n",
        "error = np.sum(error, axis=1)/X_test.T.shape[1]\n",
        "print(\"Error without Scaling: \",error*100,\"%\")"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Gradient Descent Without Scaling:\n",
            "\n",
            "Weights without scaling:\n",
            " [[ 0.04491122]\n",
            " [12.51410683]\n",
            " [ 0.17650582]\n",
            " [ 0.09924596]]\n",
            "\n",
            "Error without Scaling:  [29.91677804] %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm818sJbur8c",
        "outputId": "cc96b198-5bb3-4315-fa63-4856ead85169"
      },
      "source": [
        "print(\"Batch Gradient Descent With Scaling:\")\n",
        "print()\n",
        "batch_gradient_descent_with_scaling(X_train,Y_train,X_test,Y_test,0.01, 10000)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Gradient Descent With Scaling:\n",
            "\n",
            "Weights with scaling: \n",
            " [[63936.35340314]\n",
            " [12011.48915726]\n",
            " [ 4370.56419059]\n",
            " [ 9851.34899367]]\n",
            "\n",
            "Error with Scaling:  [18.66649001] %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-dAQdZqzEhz"
      },
      "source": [
        "def stochastic_gradient_descent(X,Y,alpha,itr):\n",
        "  W = np.zeros((n, 1))\n",
        "  for k in range(0,itr):\n",
        "      random = np.random.permutation(X.shape[1])\n",
        "      X_shuffle,Y_shuffle = X[:,random],Y[random]\n",
        "      for i in range(0,X.shape[1]):\n",
        "        x = X_shuffle[:, i].reshape((-1, 1))\n",
        "        y = Y_shuffle[i]\n",
        "        H = np.dot(W.T, x)\n",
        "        Z = H - y\n",
        "        dW = x*Z\n",
        "        W = W - alpha*dW\n",
        "  return W"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_eCGwMN1te0"
      },
      "source": [
        "def stochastic_gradient_descent_with_scaling(X_train,Y_train,X_test,Y_test,alpha,itr):\n",
        "  X_train, MEAN, STDV = scaling(X_train)\n",
        "  X_test = (X_test - MEAN) / STDV\n",
        "  X_train, X_test = X_train.T, X_test.T\n",
        "  W = np.zeros((n, 1))\n",
        "  for k in range(0, itr):\n",
        "      random = np.random.permutation(X_train.shape[1])\n",
        "      X_shuffle,Y_shuffle = X_train[:,random],Y_train[random]\n",
        "      for i in range(0,X_train.shape[1]):\n",
        "        x = X_shuffle[:, i].reshape((-1, 1))\n",
        "        y = Y_shuffle[i]\n",
        "        H = np.dot(W.T, x)\n",
        "        Z = H - y\n",
        "        dW = x*Z\n",
        "        W = W - alpha*dW\n",
        "  print(\"Weights with scaling: \\n\", W)\n",
        "  print()\n",
        "  pred = np.dot(W.T, X_test)\n",
        "  error = abs(Y_test - pred)/Y_test\n",
        "  error = np.sum(error, axis=1)/X_test.shape[1]\n",
        "  print(\"Error with Scaling: \",error*100,\"%\")"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byTCJ5slz0VI",
        "outputId": "0bbad6a6-ccd3-488f-b9d4-734401a1d8ae"
      },
      "source": [
        "print(\"Stochastic Gradient Descent Without Scaling:\")\n",
        "print()\n",
        "W = stochastic_gradient_descent(X_train.T,Y_train,0.000000001, 10000)\n",
        "print(\"Weights without scaling: \\n\", W)\n",
        "print()\n",
        "pred = np.dot(W.T, X_test.T)\n",
        "error = abs(Y_test - pred)/Y_test\n",
        "error = np.sum(error, axis=1)/X_test.T.shape[1]\n",
        "print(\"Error without Scaling: \",error*100,\"%\")"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stochastic Gradient Descent Without Scaling:\n",
            "\n",
            "Weights without scaling: \n",
            " [[16.37049285]\n",
            " [12.1799133 ]\n",
            " [65.03401314]\n",
            " [36.89751075]]\n",
            "\n",
            "Error without Scaling:  [29.77521275] %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJJQCdkj1ob7",
        "outputId": "05b38a29-6882-4dcd-9db0-78f84af45d3f"
      },
      "source": [
        "print(\"Stochastic Gradient Descent With Scaling:\")\n",
        "print()\n",
        "stochastic_gradient_descent_with_scaling(X_train,Y_train,X_test,Y_test,0.01, 10000)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stochastic Gradient Descent With Scaling:\n",
            "\n",
            "Weights with scaling: \n",
            " [[63808.06593379]\n",
            " [11961.09324613]\n",
            " [ 2649.77427355]\n",
            " [ 9326.15731255]]\n",
            "\n",
            "Error with Scaling:  [18.52232213] %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZDnqpMI4giF"
      },
      "source": [
        "def create(X, Y, sizes):\n",
        "    mini_batches = []\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    num_batches = X.shape[0] // sizes\n",
        "    i=0\n",
        "    for i in range(0,num_batches):\n",
        "      excerpt = indices[i*sizes:(i+1)*sizes]\n",
        "      X_mini,Y_mini = X[excerpt],Y[excerpt]\n",
        "      mini_batches.append((X_mini.T,Y_mini))\n",
        "\n",
        "    if X.shape[0] % sizes != 0:\n",
        "      excerpt = indices[i*sizes:(i+1)*sizes]\n",
        "      X_mini, Y_mini = X[excerpt], Y[excerpt]\n",
        "      mini_batches.append((X_mini.T, Y_mini))\n",
        "    return mini_batches"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1FaXmWy3wo2"
      },
      "source": [
        "def mini_batch_gradient_descent(X,Y,alpha,itr,sizes):\n",
        "  W = np.zeros((n, 1))\n",
        "  for i in range(0, itr):\n",
        "      mini_batches = create(X.T,Y,sizes)\n",
        "      for mini_batch in mini_batches:\n",
        "        X_mini,Y_mini = mini_batch\n",
        "        H = np.dot(W.T, X_mini)\n",
        "        Z = H - Y_mini\n",
        "        dW = np.dot(X_mini,Z.T)\n",
        "        W = W - (alpha*dW)/X_mini.shape[1]\n",
        "  return W"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keDa61z_9jS4"
      },
      "source": [
        "def mini_batch_gradient_descent_with_scaling(X_train,Y_train,X_test,Y_test,alpha,itr,sizes):\n",
        "  X_train, MEAN, STDV = scaling(X_train)\n",
        "  X_test = (X_test - MEAN) / STDV\n",
        "  X_train, X_test = X_train.T, X_test.T\n",
        "  W = np.zeros((n, 1))\n",
        "  for i in range(0, itr):\n",
        "      mini_batches = create(X_train.T,Y_train,sizes)\n",
        "      for mini_batch in mini_batches:\n",
        "        X_mini,Y_mini = mini_batch\n",
        "        H = np.dot(W.T, X_mini)\n",
        "        Z = H - Y_mini\n",
        "        dW = np.dot(X_mini,Z.T)\n",
        "        W = W - (alpha*dW)/X_mini.shape[1]\n",
        "  print(\"Weights with Scaling: \\n\", W)\n",
        "  print()\n",
        "  pred = np.dot(W.T, X_test)\n",
        "  error = abs(Y_test - pred)/Y_test\n",
        "  error = np.sum(error, axis=1)/X_test.shape[1]\n",
        "  print(\"Error with Scaling,(Batch Size = \",sizes,\"): \",error*100,\"%\")"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPTUPul23Jp5",
        "outputId": "1b6c5f7a-388a-49ee-a467-e33f24afd59d"
      },
      "source": [
        "batch = [10,20,30,40,50]\n",
        "cnt=1\n",
        "print(\"Mini Batch Gradient Descent With Scaling:\")\n",
        "print()\n",
        "for b in batch:\n",
        "  print(cnt,\". \")\n",
        "  W = mini_batch_gradient_descent(X_train.T,Y_train, 0.00000001, 10000, b)\n",
        "  print(\"Weights without Scaling: \\n\", W)\n",
        "  print()\n",
        "  pred = np.dot(W.T, X_test.T)\n",
        "  error = abs(Y_test - pred)/Y_test\n",
        "  error = np.sum(error, axis=1)/X_test.T.shape[1]\n",
        "  print(\"Error without Scaling: \",error*100,\"%\")\n",
        "  print()\n",
        "  mini_batch_gradient_descent_with_scaling(X_train,Y_train,X_test,Y_test, 0.01, 10000, b)\n",
        "  cnt+=1\n",
        "  print()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini Batch Gradient Descent With Scaling:\n",
            "\n",
            "1 . \n",
            "Weights without Scaling: \n",
            " [[16.68940469]\n",
            " [13.04351817]\n",
            " [66.29299968]\n",
            " [37.61821996]]\n",
            "\n",
            "Error without Scaling:  [30.3117148] %\n",
            "\n",
            "Weights with Scaling: \n",
            " [[63927.94372129]\n",
            " [11925.73298022]\n",
            " [ 4101.37318798]\n",
            " [ 9721.87583572]]\n",
            "\n",
            "Error with Scaling,(Batch Size =  10 ):  [18.59869597] %\n",
            "\n",
            "2 . \n",
            "Weights without Scaling: \n",
            " [[ 8.56344829]\n",
            " [13.47317054]\n",
            " [34.03523884]\n",
            " [19.302457  ]]\n",
            "\n",
            "Error without Scaling:  [31.05436088] %\n",
            "\n",
            "Weights with Scaling: \n",
            " [[63965.4099079 ]\n",
            " [11951.43234455]\n",
            " [ 4333.97386923]\n",
            " [ 9775.1804128 ]]\n",
            "\n",
            "Error with Scaling,(Batch Size =  20 ):  [18.61464485] %\n",
            "\n",
            "3 . \n",
            "Weights without Scaling: \n",
            " [[ 5.56182862]\n",
            " [12.67644664]\n",
            " [22.10659631]\n",
            " [12.54130562]]\n",
            "\n",
            "Error without Scaling:  [29.97878906] %\n",
            "\n",
            "Weights with Scaling: \n",
            " [[63896.58841718]\n",
            " [11785.5280599 ]\n",
            " [ 4330.86236784]\n",
            " [10156.28572184]]\n",
            "\n",
            "Error with Scaling,(Batch Size =  30 ):  [18.65006266] %\n",
            "\n",
            "4 . \n",
            "Weights without Scaling: \n",
            " [[ 4.27903984]\n",
            " [11.98409262]\n",
            " [17.01314142]\n",
            " [ 9.64846499]]\n",
            "\n",
            "Error without Scaling:  [29.90671912] %\n",
            "\n",
            "Weights with Scaling: \n",
            " [[63847.40536627]\n",
            " [11800.32081096]\n",
            " [ 4285.73822356]\n",
            " [ 9898.63275644]]\n",
            "\n",
            "Error with Scaling,(Batch Size =  40 ):  [18.62578368] %\n",
            "\n",
            "5 . \n",
            "Weights without Scaling: \n",
            " [[ 3.42983219]\n",
            " [13.02956279]\n",
            " [13.62805209]\n",
            " [ 7.72378066]]\n",
            "\n",
            "Error without Scaling:  [30.31923802] %\n",
            "\n",
            "Weights with Scaling: \n",
            " [[63969.10536273]\n",
            " [12190.44355839]\n",
            " [ 4353.66693601]\n",
            " [ 9908.39468657]]\n",
            "\n",
            "Error with Scaling,(Batch Size =  50 ):  [18.73196905] %\n",
            "\n"
          ]
        }
      ]
    }
  ]
}